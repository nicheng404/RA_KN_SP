{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is to get the grid level filtered tif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 拿到一个国家的shp 然后拿到 国家.geometry.bounds\n",
    "2. 对每一个 tif文件,\n",
    "    用每一个 国家 mask一下: #masked, out_transform = mask(src, [bbox], crop=True)\n",
    "        之后生成一个 masked np array\n",
    "        out_transform 是变换矩阵 #lon, lat = transform * (indexx, indexy)\n",
    "        然后 loop 这里面的point(indexx, indexy):\n",
    "            拿值 拿lonlat 拿名字 存到csv里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shapefile\n",
    "gdf = gpd.read_file('./country_poly_data/WB_countries_Admin0_10m.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get names from ISO of old world countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of countries in old world:  143\n",
      "Number of countries after merging:  142\n",
      "The following columns are missing: ['COD']\n"
     ]
    }
   ],
   "source": [
    "# Read the datasets\n",
    "country_old_world = pd.read_csv('./country_old_world.csv')\n",
    "len_old = len(country_old_world['ISO'])\n",
    "print('Number of countries in old world: ', len_old)\n",
    "country_name_codes = pd.read_csv('./country_name_codes.csv')\n",
    "\n",
    "# Perform the inner join on the 'ISO' column\n",
    "merged_data = country_old_world.merge(country_name_codes, on='ISO', suffixes=('_old', '_new'))\n",
    "len_new = len(merged_data['ISO'])\n",
    "print('Number of countries after merging: ', len_new)\n",
    "# # Save the result to a new CSV file\n",
    "# merged_data.to_csv('merged_data.csv', index=False)\n",
    "\n",
    "\n",
    "if len_old != len_new:\n",
    "        # Merge the datasets using an outer join\n",
    "    merged_df = country_old_world.merge(country_name_codes, on='ISO', how='outer', indicator=True)\n",
    "\n",
    "    # Filter the rows that are only in the 'old_world' dataset\n",
    "    missing_iso = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "    # Print the ISO codes that are in 'old_world' but not in 'country_name'\n",
    "    print('The following columns are missing:', missing_iso['ISO'].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to get the country boundaries from shp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country not found:  Cote d'Ivoire\n",
      "Country not found:  Ethiopia (excludes Eritrea)\n",
      "Country not found:  Faeroe Islands\n",
      "Country not found:  Gambia, The\n",
      "Country not found:  Kyrgyz Republic\n",
      "Country not found:  Lao PDR\n",
      "Country not found:  Macao\n",
      "Country not found:  Macedonia, FYR\n",
      "Country not found:  Sao Tome and Principe\n",
      "Country not found:  Slovak Republic\n",
      "Country not found:  Syrian Arab Republic\n",
      "Country not found:  Yemen, Rep.\n",
      "Country not found:  Yugoslavia, FR (Serbia/Montene\n"
     ]
    }
   ],
   "source": [
    "def get_country_boundary(gdf, country_name):\n",
    "    # Filter the GeoDataFrame for the specific country\n",
    "    country_gdf = gdf[gdf['NAME_EN'].str.lower() == country_name.lower()]\n",
    "    \n",
    "    if country_gdf.empty:\n",
    "        print(\"Country not found: \", country_name)\n",
    "        return None\n",
    "\n",
    "    # Return the GeoSeries of the country boundary geometry\n",
    "    return country_gdf.geometry\n",
    "\n",
    "# Initialize an empty dictionary to store country boundaries\n",
    "# Store all the boundaries required.\n",
    "country_boundaries = {}\n",
    "\n",
    "# Loop through the merged_data DataFrame\n",
    "# Get all needed countries' boundary boxed into a dict.\n",
    "for index, row in merged_data.iterrows():\n",
    "    country_name = row['Country_name']\n",
    "    country_geometry = get_country_boundary(gdf, country_name)\n",
    "\n",
    "    if country_geometry is not None:\n",
    "        minx, miny, maxx, maxy = country_geometry.total_bounds\n",
    "        bbox = box(minx, miny, maxx, maxy)\n",
    "        \n",
    "        country_boundaries[country_name] = bbox\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 拿到一个国家的shp 然后拿到 国家.geometry.total bounds\n",
    "2. 对每一个 tif文件,\n",
    "    用每一个 国家 mask一下: #masked_img, out_transform = mask(src, [boundary_box], crop=True)\n",
    "        之后生成一个 masked np array\n",
    "        out_transform 是变换矩阵 #lon, lat = transform * (indexx, indexy)\n",
    "        然后 loop 这里面的point(indexx, indexy):\n",
    "            拿值 拿lonlat 拿名字 存到csv里"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for:  ./data/F101992.v4b_web.stable_lights.avg_vis.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_name = 'F101992.v4b_web.stable_lights'\n",
    "tif_file ='./data/F101992.v4b_web.stable_lights.avg_vis.tif'\n",
    "# Load the tif data using the rasterio module\n",
    "with rasterio.open(tif_file) as src:\n",
    "    # Make a list to save the latitude, longitude, value, and country_name \n",
    "    csv_rows = []\n",
    "    \n",
    "    #  loop through the dict of {country_name : boundary_box}\n",
    "    for country_name, boundary_box in country_boundaries.items():\n",
    "        # filter the tif file.\n",
    "        # 'masked_img' is the filtered tif data. shape = (1, height, length)\n",
    "        # 'out_transform' is transform matrix, which uses the index of pixel to get its real lat/lon.\n",
    "        # Get the pixel level first then sample them to be the 5-5 grid level (using the result = matrix[::5, ::5] )\n",
    "        masked_img, out_transform = mask(src, [boundary_box], crop=True)\n",
    "        masked_values = masked_img[0]\n",
    "\n",
    "        # TODO: after using the np to replace the for loop, get the value with two matrixes.\n",
    "        # Get the cols and rows matrix for each pixel\n",
    "        cols, rows =  np.meshgrid(np.arange(masked_values.shape[1]),np.arange(masked_values.shape[0]))\n",
    "        # Turn to real lon lat for each index. Get location first then do the sampling.\n",
    "        # lon.shape = 1092, 1730 = lat.shape\n",
    "        lon, lat = rasterio.transform.xy(out_transform, rows, cols)\n",
    "        lon = np.array(lon)\n",
    "        lat = np.array(lat)\n",
    "\n",
    "        # Sample the values and lat lon for every 5th point to be a 5-5 grid.\n",
    "        # The following 3 matrixes are linked together. 对应位置一一对照\n",
    "        masked_values_sampled = masked_values[::5, ::5] # e.g. masked_values_sampled[x,y] = 10. This means masked_values_sampled[x,y]'s real value is 10.\n",
    "        lon_sampled = lon[::5, ::5] # e.g. lon_sampled[x,y] = 3. This means lon_sampled[x,y]'s real lon is 3.\n",
    "        lat_sampled = lat[::5, ::5] # e.g. lat_sampled[x,y] = 4. This means lat_sampled[x,y]'s real lat is 4. \n",
    "\n",
    "        \n",
    "\n",
    "        # Loop each item\n",
    "        for i in range(masked_values_sampled.shape[0]):\n",
    "            for j in range(masked_values_sampled.shape[1]):\n",
    "                point_lon = lon_sampled[i,j]\n",
    "                point_lat = lat_sampled[i,j]\n",
    "                point_value = masked_values_sampled[i,j]\n",
    "\n",
    "                \n",
    "                csv_rows.append((point_lat, point_lon, point_value, country_name))\n",
    "\n",
    "\n",
    "    # Save the data of csv_rows into a csv file        \n",
    "    # Write the list to a CSV file with the same name as the tif file\n",
    "    with open(f'./extracted_data/{file_name}.csv', 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['latitude', 'longitude', 'value', 'country_name'])\n",
    "        csv_writer.writerows(csv_rows)\n",
    "    print('Finished for: ', tif_file)        \n",
    "\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for:  ./data/F152000.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F142000.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F142002.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F101992.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152002.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F142001.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152001.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152003.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F101993.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F142003.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162008.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121998.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152005.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162005.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F141998.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121995.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121997.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162007.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152007.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F182010.v4d_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F182012.v4c_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F141997.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121999.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162009.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F182011.v4c_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152004.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F101994.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121994.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162004.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F141999.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F162006.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F121996.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F152006.v4b_web.stable_lights.avg_vis.tif\n",
      "Finished for:  ./data/F182013.v4c_web.stable_lights.avg_vis.tif\n"
     ]
    }
   ],
   "source": [
    "# Loop all the tif files in the folder \n",
    "for tif_file in glob.glob('./data/*.tif'):\n",
    "    # Get the file name without the extension.\n",
    "    # Use the name to save the filtered data later.\n",
    "    file_name = os.path.splitext(os.path.basename(tif_file))[0]\n",
    "\n",
    "    # Load the tif data using the rasterio module\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        # Make a list to save the latitude, longitude, value, and country_name \n",
    "        csv_rows = []\n",
    "        \n",
    "        #  loop through the dict of {country_name : boundary_box}\n",
    "        for country_name, boundary_box in country_boundaries.items():\n",
    "            # filter the tif file.\n",
    "            # 'masked_img' is the filtered tif data. shape = (1, height, length)\n",
    "            # 'out_transform' is transform matrix, which uses the index of pixel to get its real lat/lon.\n",
    "            # Get the pixel level first then sample them to be the 5-5 grid level (using the result = matrix[::5, ::5] )\n",
    "            masked_img, out_transform = mask(src, [boundary_box], crop=True)\n",
    "            masked_values = masked_img[0]\n",
    "\n",
    "            # TODO: after using the np to replace the for loop, get the value with two matrixes.\n",
    "            # Get the cols and rows matrix for each pixel\n",
    "            cols, rows =  np.meshgrid(np.arange(masked_values.shape[1]),np.arange(masked_values.shape[0]))\n",
    "            # Turn to real lon lat for each index. Get location first then do the sampling.\n",
    "            # lon.shape = 1092, 1730 = lat.shape\n",
    "            lon, lat = rasterio.transform.xy(out_transform, rows, cols)\n",
    "            lon = np.array(lon)\n",
    "            lat = np.array(lat)\n",
    "\n",
    "            # Sample the values and lat lon for every 5th point to be a 5-5 grid.\n",
    "            # The following 3 matrixes are linked together. 对应位置一一对照\n",
    "            masked_values_sampled = masked_values[::5, ::5] # e.g. masked_values_sampled[x,y] = 10. This means masked_values_sampled[x,y]'s real value is 10.\n",
    "            lon_sampled = lon[::5, ::5] # e.g. lon_sampled[x,y] = 3. This means lon_sampled[x,y]'s real lon is 3.\n",
    "            lat_sampled = lat[::5, ::5] # e.g. lat_sampled[x,y] = 4. This means lat_sampled[x,y]'s real lat is 4. \n",
    "\n",
    "            \n",
    "\n",
    "            # Loop each item\n",
    "            for i in range(masked_values_sampled.shape[0]):\n",
    "                for j in range(masked_values_sampled.shape[1]):\n",
    "                    point_lon = lon_sampled[i,j]\n",
    "                    point_lat = lat_sampled[i,j]\n",
    "                    point_value = masked_values_sampled[i,j]\n",
    "\n",
    "                    csv_rows.append((point_lat, point_lon, point_value, country_name))\n",
    "\n",
    "\n",
    "        # Save the data of csv_rows into a csv file        \n",
    "        # Write the list to a CSV file with the same name as the tif file\n",
    "        with open(f'./extracted_data/{file_name}.csv', 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['latitude', 'longitude', 'value', 'country_name'])\n",
    "            csv_writer.writerows(csv_rows)\n",
    "        print('Finished for: ', tif_file)     \n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
